{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vision_transformer_haiku_tpu",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "dzrYLn_gAfpc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet dm-haiku"
      ],
      "metadata": {
        "id": "aYJQTd1bWVVQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eNLd4QKVWLd7"
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "import functools\n",
        "\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "import haiku as hk\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets setup"
      ],
      "metadata": {
        "id": "bKOIq8BKXtv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "ds_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R12bCboPWvTV",
        "outputId": "fa60cd7f-7d6b-4765-e294-3a30107e43ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='mnist',\n",
              "    version=3.0.1,\n",
              "    description='The MNIST database of handwritten digits.',\n",
              "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
              "    }),\n",
              "    total_num_examples=70000,\n",
              "    splits={\n",
              "        'test': 10000,\n",
              "        'train': 60000,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@article{lecun2010mnist,\n",
              "      title={MNIST handwritten digit database},\n",
              "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
              "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
              "      volume={2},\n",
              "      year={2010}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(128, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "o-rgkdFfXItS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(ds_train))\n",
        "x.shape, type(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPYKns8aXJ61",
        "outputId": "94248bc9-5682-45eb-d07e-ed21bcb97ebb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 28, 28, 1]), tensorflow.python.framework.ops.EagerTensor)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(tfds.as_numpy(ds_train)))\n",
        "x.shape, type(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0C02aGo_ajT",
        "outputId": "27c3c8cb-9e79-4373-e0b3-27c8b3bce13f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((128, 28, 28, 1), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Haiku"
      ],
      "metadata": {
        "id": "glq16DqH_q2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclasses.dataclass\n",
        "class Tokenizer(hk.Module):\n",
        "  embed_dim: int\n",
        "\n",
        "  def __call__(self, img: jnp.array):\n",
        "    emb = hk.Conv2D(self.embed_dim, kernel_shape=4, stride=4)(img)\n",
        "    w, h, d = emb.shape\n",
        "    return jnp.reshape(emb, (w * h, d))\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class MLP(hk.Module):\n",
        "  embed_dim: int\n",
        "  expand_factor: int\n",
        "  init_fn: hk.initializers.Initializer\n",
        "\n",
        "  def __call__(self, tokens: jnp.array):\n",
        "    tokens = hk.Linear(self.embed_dim * self.expand_factor, w_init=self.init_fn)(tokens)\n",
        "    tokens = jax.nn.gelu(tokens)\n",
        "    return hk.Linear(self.embed_dim, w_init=self.init_fn)(tokens)\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class MultiHeadsSelfAtt(hk.Module):\n",
        "  embed_dim: int\n",
        "  nb_heads: int\n",
        "  init_fn: hk.initializers.Initializer\n",
        "\n",
        "  def __call__(self, tokens: jnp.array):\n",
        "    qkv = hk.Linear(3 * self.embed_dim, w_init=self.init_fn)(tokens)\n",
        "    q, k, v = jnp.split(qkv, indices_or_sections=3, axis=-1)\n",
        "\n",
        "    q = jnp.reshape(q, (-1, self.nb_heads, self.embed_dim // self.nb_heads))\n",
        "    k = jnp.reshape(k, (-1, self.nb_heads, self.embed_dim // self.nb_heads))\n",
        "    v = jnp.reshape(v, (-1, self.nb_heads, self.embed_dim // self.nb_heads))\n",
        "\n",
        "    o = _mhsa(q, k, v)\n",
        "\n",
        "    return hk.Linear(self.embed_dim, w_init=self.init_fn)(o)\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class MultiHeadsClassAtt(hk.Module):\n",
        "  embed_dim: int\n",
        "  nb_heads: int\n",
        "  init_fn: hk.initializers.Initializer\n",
        "\n",
        "  def __call__(self, tokens: jnp.array):\n",
        "    qkv = hk.Linear(3 * self.embed_dim, w_init=self.init_fn)(tokens)\n",
        "    q, k, v = jnp.split(qkv, indices_or_sections=3, axis=-1)\n",
        "\n",
        "    q = jnp.reshape(q[0], (1, self.nb_heads, self.embed_dim // self.nb_heads))\n",
        "    k = jnp.reshape(k, (-1, self.nb_heads, self.embed_dim // self.nb_heads))\n",
        "    v = jnp.reshape(v, (-1, self.nb_heads, self.embed_dim // self.nb_heads))\n",
        "\n",
        "    o = _mhsa(q, k, v)\n",
        "\n",
        "    return hk.Linear(self.embed_dim, w_init=self.init_fn)(o)\n",
        "\n",
        "@jax.jit\n",
        "def _mhsa(q, k, v) -> jnp.array:\n",
        "    embed_dim = q.shape[-1] * q.shape[-2]\n",
        "\n",
        "    att_logits = jnp.einsum('...thd,...Thd->...htT', q, k)\n",
        "    # eq. to jnp.matmul(x.transpose(1,0,2), y.transpose(1, 2, 0))\n",
        "    scale = 1 / jnp.sqrt(embed_dim)\n",
        "    att = jax.nn.softmax(att_logits * scale)\n",
        "\n",
        "    o = jnp.einsum(\"...htT,...Thd->...thd\", att, v)\n",
        "    # eq. to jnp.matmul(x, y.transpose(1, 0, 2)).transpose(1, 0, 2)\n",
        "    o = jnp.reshape(o, (-1, embed_dim))\n",
        "\n",
        "    return o\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Block(hk.Module):\n",
        "    embed_dim: int\n",
        "    nb_heads: int\n",
        "    init_fn: hk.initializers.Initializer\n",
        "    att_fn: hk.Module\n",
        "    expand_factor: int\n",
        "\n",
        "    def __call__(self, tokens):\n",
        "      tokens_ = hk.LayerNorm(-1, create_scale=True, create_offset=True)(tokens)\n",
        "      tokens_ = self.att_fn(self.embed_dim, self.nb_heads, self.init_fn)(tokens_)\n",
        "\n",
        "      tokens = tokens + tokens_\n",
        "\n",
        "      tokens_ = hk.LayerNorm(-1, create_scale=True, create_offset=True)(tokens)\n",
        "      tokens_ = MLP(self.embed_dim, self.expand_factor, self.init_fn)(tokens_)\n",
        "\n",
        "      return tokens + tokens_\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class PosEmbedding(hk.Module):\n",
        "  def __call__(self, tokens: jnp.array):\n",
        "    init = hk.initializers.TruncatedNormal(stddev=0.02)\n",
        "    pos_emb = hk.get_parameter(\"pos_emb\", tokens.shape, init=init)\n",
        "    return tokens + pos_emb\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class ViT(hk.Module):\n",
        "  embed_dim: int\n",
        "  expand_factor: int\n",
        "  nb_layers: int\n",
        "  nb_heads: int\n",
        "  nb_classes: int\n",
        "  nb_ca: int = 1\n",
        "  cait: bool = False\n",
        "\n",
        "  def __call__(self, img):\n",
        "    tokens = Tokenizer(self.embed_dim)(img)\n",
        "\n",
        "    init_token = hk.initializers.TruncatedNormal(stddev=0.02)\n",
        "    init_var = hk.initializers.VarianceScaling(2 / self.nb_layers)\n",
        "\n",
        "    cls_token = hk.get_parameter(\"cls_token\", (1, self.embed_dim), init=init_token)\n",
        "\n",
        "    if self.cait:\n",
        "      tokens = PosEmbedding()(tokens)\n",
        "\n",
        "      for _ in range(self.nb_layers - self.nb_ca):\n",
        "        tokens = Block(\n",
        "            self.embed_dim, self.nb_heads, init_var, MultiHeadsSelfAtt, self.expand_factor\n",
        "        )(tokens)\n",
        "\n",
        "      for _ in range(self.nb_ca):\n",
        "        tokens = jnp.concatenate((cls_token, tokens))\n",
        "        cls_token = Block(\n",
        "            self.embed_dim, self.nb_heads, init_var, MultiHeadsClassAtt, self.expand_factor\n",
        "        )(tokens)\n",
        "\n",
        "      final_emb = cls_token[0]\n",
        "    else:\n",
        "      tokens = jnp.concatenate((cls_token, tokens))\n",
        "      tokens = PosEmbedding()(tokens)\n",
        "\n",
        "      for _ in range(self.nb_layers):\n",
        "        tokens = Block(\n",
        "            self.embed_dim, self.nb_heads, init_var, MultiHeadsSelfAtt, self.expand_factor\n",
        "        )(tokens)\n",
        "\n",
        "      final_emb = tokens[0]\n",
        "\n",
        "    return hk.Linear(\n",
        "        self.nb_classes, w_init=init_var\n",
        "    )(hk.LayerNorm(-1, create_scale=True, create_offset=True)(final_emb))\n",
        "\n",
        "\n",
        "def _vit(x):\n",
        "  return ViT(\n",
        "      embed_dim=10, \n",
        "      expand_factor=4,\n",
        "      nb_layers=3,\n",
        "      nb_heads=2, \n",
        "      nb_classes=10,\n",
        "      nb_ca=1,\n",
        "      cait=True\n",
        "  )(x)"
      ],
      "metadata": {
        "id": "iqftIU9o-Ush"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_devices = len(jax.devices())\n",
        "jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFsir4N0B4Yw",
        "outputId": "671fa6e6-5bc1-4ed7-b8d4-3ac1e1baf5e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rng = jax.random.PRNGKey(1)\n",
        "keys = jax.random.split(rng, len(jax.devices()))\n",
        "\n",
        "vit = hk.without_apply_rng(hk.transform(_vit))\n",
        "\n",
        "dummy_x = jnp.ones((28, 28, 1))\n",
        "params = vit.init(rng, dummy_x)"
      ],
      "metadata": {
        "id": "nK-i89BrB7aa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_params = jax.tree_map(lambda x: jnp.array([x] * nb_devices), params)"
      ],
      "metadata": {
        "id": "tWvf6PpICxj_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batched = jax.jit(jax.vmap(vit.apply, axis_name=\"batch\", in_axes=(None, 0)))\n",
        "dist_batched = jax.pmap(batched, axis_name=\"device\")\n",
        "dist_batched_not_replicated = jax.pmap(batched, in_axes=(None, 0))\n",
        "\n",
        "dist_batched(dist_params, jnp.ones((8, 32, 28, 28, 1))).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_rSH432KGrc",
        "outputId": "7cd68edb-36c1-4873-f38f-dd8b353ebb82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 32, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = jnp.ones((8, 4096, 28, 28, 1))"
      ],
      "metadata": {
        "id": "UhBILRhDrS9j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit dist_batched(dist_params, x).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNzDTJY1ADm4",
        "outputId": "250e9ed3-78b2-4c0d-fd5c-d251257ee721"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 16.66 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 204 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit dist_batched_not_replicated(params, x).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsdX_cJhrM_P",
        "outputId": "60ef699d-b490-4e68-81c8-286d27d24db6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 17.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 207 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j_dist_batched = jax.jit(dist_batched)\n",
        "\n",
        "%timeit j_dist_batched(dist_params, x).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2D3P6uuRADZ",
        "outputId": "881e8270-366a-43b7-8d17-887999ed8df3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py:342: UserWarning: The jitted function apply_fn includes a pmap. Using jit-of-pmap can lead to inefficient data movement, as the outer jit does not preserve sharded data representations and instead collects input and output arrays onto a single device. Consider removing the outer jit unless you know what you're doing. See https://github.com/google/jax/issues/2926.\n",
            "  f\"The jitted function {name} includes a pmap. Using \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 13.70 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 273 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "4iv4e59RGVH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train = tfds.as_numpy(ds_train)\n",
        "loader_test = tfds.as_numpy(ds_test)"
      ],
      "metadata": {
        "id": "-BXjbbSGvPpM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_sharded(x):\n",
        "  b, *shp = x.shape\n",
        "  d = len(jax.devices())\n",
        "  return jnp.reshape(x, (d, b // d, *shp))\n",
        "\n",
        "\n",
        "def loss_fn(params, xs, ys):\n",
        "  logits = batched(params, xs)\n",
        "  labels = jax.nn.one_hot(ys, 10)\n",
        "  log_likelihood = jnp.mean(jnp.sum(labels * jax.nn.log_softmax(logits), -1))\n",
        "  return -log_likelihood\n",
        "\n",
        "\n",
        "@functools.partial(jax.pmap, axis_name=\"nb_devices\")\n",
        "def update(params, xs, ys):\n",
        "  loss, grads = jax.value_and_grad(loss_fn)(params, xs, ys)\n",
        "\n",
        "  loss = jax.lax.pmean(loss, axis_name=\"nb_devices\")\n",
        "  grads = jax.lax.pmean(grads, axis_name=\"nb_devices\")\n",
        "\n",
        "  new_params = jax.tree_map(\n",
        "      lambda p, g: p - 0.05 * g,\n",
        "      params, grads\n",
        "  )\n",
        "  return new_params, loss\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def _eval(params, xs, ys, result, count):\n",
        "    yhat = jnp.argmax(batched(params, xs), -1)\n",
        "    result += jnp.sum(yhat == ys)\n",
        "    count += len(ys)\n",
        "    return result, count\n",
        "\n",
        "\n",
        "def eval(params, loader):\n",
        "  result, count = jnp.array(0.), jnp.array(0.)\n",
        "\n",
        "  for xs, ys in loader:\n",
        "    result, count = _eval(params, xs, ys, result, count)\n",
        "\n",
        "  return 100 * result / count"
      ],
      "metadata": {
        "id": "lrRaXm4kGvpU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = vit.init(rng, jnp.ones((28, 28, 1)))\n",
        "dist_params = jax.tree_map(lambda x: jnp.array([x] * nb_devices), params)"
      ],
      "metadata": {
        "id": "AAMiAPFnoR3w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  mean_loss, c = jnp.array(0.), 0\n",
        "  for xs, ys in loader_train:\n",
        "    dist_params, loss = update(dist_params, to_sharded(xs), to_sharded(ys))\n",
        "    mean_loss += loss[0]\n",
        "    c += 1\n",
        "\n",
        "  params = jax.device_get(jax.tree_map(lambda x: x[0], dist_params))\n",
        "  print(f\"[{epoch}] Mean train loss: {round(mean_loss / c, 5)}\")\n",
        "  print(f\"[{epoch}] Train accuracy: {round(float(eval(params, loader_train)), 2)}\")\n",
        "\n",
        "print(f\"[{epoch}] Test accuracy: {round(float(eval(params, loader_test)), 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ti2desmQ6Af",
        "outputId": "3db5abbd-542b-44c2-f67d-c54dcbd30e05"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Mean train loss: 2.1996798515319824\n",
            "[0] Train accuracy: 24.71\n",
            "[1] Mean train loss: 1.5767399072647095\n",
            "[1] Train accuracy: 63.02\n",
            "[2] Mean train loss: 0.9171499609947205\n",
            "[2] Train accuracy: 72.03\n",
            "[3] Mean train loss: 0.6782900094985962\n",
            "[3] Train accuracy: 83.51\n",
            "[4] Mean train loss: 0.5320799946784973\n",
            "[4] Train accuracy: 85.68\n",
            "[5] Mean train loss: 0.4148799777030945\n",
            "[5] Train accuracy: 88.36\n",
            "[6] Mean train loss: 0.3565099835395813\n",
            "[6] Train accuracy: 88.4\n",
            "[7] Mean train loss: 0.305869996547699\n",
            "[7] Train accuracy: 90.83\n",
            "[8] Mean train loss: 0.27741000056266785\n",
            "[8] Train accuracy: 92.3\n",
            "[9] Mean train loss: 0.24948999285697937\n",
            "[9] Train accuracy: 92.51\n",
            "[9] Test accuracy: 92.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_0 = jax.device_get(jax.tree_map(lambda x: x[0], dist_params))\n",
        "print(f\"[{epoch}] Train accuracy: {round(float(eval(params_0, loader_train)), 2)}\")"
      ],
      "metadata": {
        "id": "f0RGWw3wsnro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7660c94a-1fed-4eb2-915f-004acb81b3c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9] Train accuracy: 92.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_1 = jax.device_get(jax.tree_map(lambda x: x[1], dist_params))\n",
        "print(f\"[{epoch}] Train accuracy: {round(float(eval(params_1, loader_train)), 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mnV5YxesoDD",
        "outputId": "24099ba2-797c-4f5e-b24e-c55e6979f1d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9] Train accuracy: 92.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.allclose(params_0[\"vi_t/linear\"][\"w\"], params_1[\"vi_t/linear\"][\"w\"])"
      ],
      "metadata": {
        "id": "OhknubpZsv-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94198a5b-766d-4eae-f988-87088513771a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(True, dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eNMMj5JixXoU"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}